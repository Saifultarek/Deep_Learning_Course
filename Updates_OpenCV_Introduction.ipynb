{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pk3z02t7C7xd"
      },
      "source": [
        "Some important basic terms and concepts related to OpenCV:\n",
        "\n",
        "1. **Image:** In OpenCV, an image is a two-dimensional array of pixels that can be either grayscale or color (BGR or RGB).\n",
        "\n",
        "2. **ROI (Region of Interest):** A region of interest is a specific area within an image where you want to perform a particular operation or analysis.\n",
        "\n",
        "3. **Channel:** In color images, each color (e.g., red, green, and blue) is represented as a separate channel. OpenCV allows you to manipulate these channels individually.\n",
        "\n",
        "4. **Grayscale:** A grayscale image is a single-channel image where pixel values represent intensity, typically in the range 0 to 255.\n",
        "\n",
        "5. **Histogram:** A histogram is a graphical representation of the distribution of pixel values in an image. It's often used for image analysis and processing.\n",
        "\n",
        "6. **Thresholding:** Thresholding is a technique used to segment an image by separating pixels into two groups based on their intensity values. It's commonly used for object detection and image segmentation.\n",
        "\n",
        "7. **Contour:** A contour is a curve that connects continuous points along the boundary of an object in an image. Contours are used for object detection and shape analysis.\n",
        "\n",
        "8. **Filter/Kernel:** In image processing, filters (or kernels) are small matrices used to perform operations like blurring, sharpening, edge detection, and more.\n",
        "\n",
        "9. **Morphological Operations:** Morphological operations include dilation and erosion, which are used to manipulate the shape and structure of objects in binary images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOCESyt0C7xm"
      },
      "outputs": [],
      "source": [
        "#!pip install python-opencv / opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AbNAl0XgC7xp"
      },
      "outputs": [],
      "source": [
        "import cv2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IBZ1H_vRC7xq",
        "outputId": "7e564e4c-4ae7-4f45-ea13-2452e4f818fe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'4.8.1'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cv2.__version__"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AIchqALnC7xs"
      },
      "outputs": [],
      "source": [
        "#Image Read\n",
        "imagedata = cv2.imread(\"./Cats.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97lDEnnfC7xt"
      },
      "outputs": [],
      "source": [
        "#print(imagedata)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yKI4CsDC7xu",
        "outputId": "bb30b97a-ce05-4ac7-b668-f91fcce01c89"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ]
        }
      ],
      "source": [
        "print(type(imagedata))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wRh9uC-AC7xv",
        "outputId": "ec4481fb-044e-4b61-e5fe-aaddc4db57a5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(698, 606, 3)"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "imagedata.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "blK24HjvC7xw",
        "outputId": "ea6583b2-4d61-44ed-d1c8-92079249b708"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "241"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "max(imagedata[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1h1qg93NC7xx"
      },
      "outputs": [],
      "source": [
        "cv2.imshow(\"Cat Image\",imagedata)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6rWbzgHlC7xy",
        "outputId": "0cb48471-9a81-46f4-d115-a3d68873604d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image datasets shape with RGB:  (698, 606, 3)\n",
            "Image datasets shape with RGB:  (698, 606)\n"
          ]
        }
      ],
      "source": [
        "imagedatasets = cv2.imread(\"./Cats.jpg\")\n",
        "print(\"Image datasets shape with RGB: \", imagedatasets.shape)\n",
        "convertBGRimageTOgrayscalle = cv2.cvtColor(imagedatasets, cv2.COLOR_BGR2GRAY)\n",
        "print(\"Image datasets shape with RGB: \", convertBGRimageTOgrayscalle.shape)\n",
        "cv2.imshow(\"Color Conversion Form BGR to Gray\",imagedata)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYScTz2PC7xy"
      },
      "source": [
        "In this example, `cv2.imshow(\"Color Conversion Form BGR to Gray\",imagedata)` displays the image in a window, and `cv2.waitKey(0)` waits indefinitely for a key press. After that, `cv2.destroyAllWindows()` is called to close the open window. If you didn't call `cv2.destroyAllWindows()`, the window might remain open after the script has finished executing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJEHHxTJC7xz",
        "outputId": "7eaaeacb-8a4a-43ce-f75b-b2f48d36b116"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1268964"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "698*606*3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3OfND6RC7xz",
        "outputId": "c23b5650-d28e-4f0e-ec39-e63cde426639"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image datasets shape with RGB:  (698, 606)\n"
          ]
        }
      ],
      "source": [
        "imagedatasets = cv2.imread(\"./Cats.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "print(\"Image datasets shape with RGB: \", imagedatasets.shape)\n",
        "#convertBGRimageTOgrayscalle = cv2.cvtColor(imagedatasets, cv2.COLOR_BGR2GRAY)\n",
        "#print(\"Image datasets shape with RGB: \", convertBGRimageTOgrayscalle.shape)\n",
        "cv2.imshow(\"Color Conversion Form BGR to Gray\",imagedatasets)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "12TmWkXSC7x0",
        "outputId": "c15ae41f-5af4-4126-f441-5ed702aa9356"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image datasets shape with RGB:  (698, 606)\n"
          ]
        }
      ],
      "source": [
        "imagedatasets = cv2.imread(\"./Cats.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "print(\"Image datasets shape with RGB: \", imagedatasets.shape)\n",
        "#convertBGRimageTOgrayscalle = cv2.cvtColor(imagedatasets, cv2.COLOR_BGR2GRAY)\n",
        "#print(\"Image datasets shape with RGB: \", convertBGRimageTOgrayscalle.shape)\n",
        "cv2.imshow(\"Color Conversion Form BGR to Gray\",imagedatasets)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3a7jn22lC7x0"
      },
      "source": [
        "## Threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhgu1v5oC7x1",
        "outputId": "ec8f94da-48fb-4fe9-bcf9-89fd7a6dd1f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image datasets shape with RGB:  (698, 606)\n"
          ]
        }
      ],
      "source": [
        "imagedatasets = cv2.imread(\"./Cats.jpg\", cv2.IMREAD_GRAYSCALE)\n",
        "print(\"Image datasets shape with RGB: \", imagedatasets.shape)\n",
        "_, imagethreshold = cv2.threshold(imagedatasets, 50, 200, cv2.THRESH_BINARY)\n",
        "#print(\"Image datasets shape with RGB: \", convertBGRimageTOgrayscalle.shape)\n",
        "cv2.imshow(\"Color Conversion Form BGR to Gray\",imagethreshold)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-HFbh010C7x1"
      },
      "source": [
        "The `cv2.drawContours` function in OpenCV is used to draw contours on an image. Contours are the boundaries of objects in an image, and this function allows you to visually highlight or mark those contours.\n",
        "\n",
        "Here's an explanation of the parameters of the `cv2.drawContours` function:\n",
        "\n",
        "- `image`: This is the image on which you want to draw the contours. It should be a color image (BGR or RGB).\n",
        "\n",
        "- `contours`: This is a Python list of contours that you want to draw on the image. Each contour is represented as a list of points, where each point is a tuple (x, y). Contours are typically obtained using functions like `cv2.findContours` and represent the boundaries of objects in the image.\n",
        "\n",
        "- `-1`: The `-1` value indicates that you want to draw all the contours provided in the `contours` list. If you want to draw a specific contour from the list, you can specify its index instead of `-1`.\n",
        "\n",
        "- `(0, 255, 0)`: This is the color you want to use for drawing the contours. In this example, `(0, 255, 0)` represents the color green in BGR format, which is often used for drawing contours. You can change these values to specify a different color.\n",
        "\n",
        "- `2`: This is the thickness of the contour lines. You can change this value to make the contours thicker or thinner based on your preference.\n",
        "\n",
        "When you call `cv2.drawContours(image, contours, -1, (0, 255, 0), 2)`, it will draw all the contours in the `contours` list on the `image` using green lines with a thickness of 2. This is a common way to visualize the detected contours in an image, which can be useful for tasks such as object detection, shape analysis, and image segmentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ss7R-X1LC7x2",
        "outputId": "c278d0f0-d3cf-4731-d35a-8d4a7bd9e02e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Image datasets shape with RGB:  (698, 606, 3)\n"
          ]
        }
      ],
      "source": [
        "imagedatasets = cv2.imread(\"./Cats.jpg\")\n",
        "print(\"Image datasets shape with RGB: \", imagedatasets.shape)\n",
        "convertBGRimageTOgrayscalle = cv2.cvtColor(imagedatasets, cv2.COLOR_BGR2GRAY)\n",
        "imageContour, _ = cv2.findContours(convertBGRimageTOgrayscalle, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "cv2.drawContours(imagedatasets, imageContour, -1, (0, 255, 0), 50)\n",
        "cv2.imshow(\"Color Conversion Form BGR to Gray\",imagedatasets)\n",
        "cv2.waitKey(0)\n",
        "cv2.destroyAllWindows()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkSMIHHHC7x2"
      },
      "source": [
        "# Imporant Notes:\n",
        "\n",
        "### 1. `cv2.waitKey(0)`\n",
        "\n",
        "Here's how it works:\n",
        "\n",
        "- `cv2.waitKey(0)` will display the image or video frame (or any graphical window created by OpenCV) and then wait for user input. The argument `0` indicates that it will wait indefinitely until a key is pressed.\n",
        "\n",
        "- When a key is pressed, the function returns the ASCII value of the key (or -1 if no key is pressed).\n",
        "\n",
        "- You can use the returned value to perform specific actions based on user input. For example, you can use it to close the window, move to the next frame in a video, or trigger some other event.\n",
        "\n",
        "\n",
        "### 2. `cv2.destroyAllWindows()`\n",
        "\n",
        "- When you use `cv2.imshow()` to display an image or any visual output, it opens a window to display the content. These windows may include images, video frames, or graphical plots.\n",
        "\n",
        "- `cv2.destroyAllWindows()` is often called after you have finished viewing and processing an image or a series of images, typically after a call to `cv2.waitKey()` that waits for a specified amount of time or for a user to press a key. It helps clean up any open windows, preventing them from lingering after your program has finished executing.\n",
        "\n",
        "### 3. `cv2.findContours`\n",
        "\n",
        "`cv2.findContours` is a function in the OpenCV library that is used for detecting and extracting contours from binary images or images with clearly defined object boundaries.\n",
        "\n",
        "`cv2.findContours` function and its parameters:\n",
        "\n",
        "```python\n",
        "contours, hierarchy = cv2.findContours(image, mode, method, offset)\n",
        "```\n",
        "\n",
        "- `image`: This is the input image from which you want to find contours. It should be a grayscale or binary image where the objects are typically represented as white and the background as black.\n",
        "\n",
        "- `mode`: This parameter specifies the retrieval mode for the contours. It determines how the contours are retrieved and how they are stored. Common modes include:\n",
        "  - `cv2.RETR_EXTERNAL`: Retrieves only the external (outer) contours.\n",
        "  - `cv2.RETR_LIST`: Retrieves all of the contours without establishing any hierarchy.\n",
        "  - `cv2.RETR_TREE`: Retrieves all of the contours and reconstructs a full hierarchy of nested contours.\n",
        "\n",
        "- `method`: This parameter specifies the contour approximation method. Common methods include:\n",
        "  - `cv2.CHAIN_APPROX_SIMPLE`: Compresses horizontal, diagonal, and vertical segments and leaves only their end points. For example, a straight line will be stored as two endpoints.\n",
        "  - `cv2.CHAIN_APPROX_NONE`: Stores all the boundary points.\n",
        "\n",
        "- `offset` (optional): This parameter allows you to specify an optional offset to be added to all the contour points. This is useful when you need to shift the contours' coordinates.\n",
        "\n",
        "The `cv2.findContours` function returns two values:\n",
        "- `contours`: A list of contours, where each contour is represented as a list of points (x, y).\n",
        "- `hierarchy`: A representation of the hierarchical relationship between the contours, which can be useful for understanding the nesting of contours.\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "deeplearning",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.16"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}